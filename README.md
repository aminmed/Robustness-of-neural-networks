# Bayesian adversarial training as defense against white-box attacks
Here is an implementation of adversarial training for image classification which is designed to defend against white box attacks, specifically FGSM, L2 PGD, and Linf PGD. It is built using the CIFAR dataset and includes the following model architectures:

- The initial model provided in the lecture.

- Residual Networks.

- VGGs

- Byesian Neural Networks

Our implementation is based on python and it's inspired from this articles:
- Towards Deep Learning Models Resistant to Adversarial Attacks: https://arxiv.org/pdf/1706.06083.pdf

- Robustness of Bayesian Neural Networks to White-Box Adversarial Attacks: https://arxiv.org/pdf/2111.08591.pdf


and these githubs: 

- https://github.com/ndb796/Pytorch-Adversarial-Training-CIFAR


## Dependencies:
 ````
 numpy, pandas, pytorch, torchvision
 ```` 
 
## How to train ?


## How to test ?

## Contributors :

  - BENCHEIKH LEHOCINE Mohammed Amine
  
  - DJECTA Hibat_Errahmen
  
  - KHEDIM Ibtissem
  
